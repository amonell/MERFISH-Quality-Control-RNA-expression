{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the experiment to analyze for bit error, codebooks, and bulk rna-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_folder = r\"D:\\MERFISH\\Archived_Experiments\\E20190919_R0003\\MERlin_Analysis\\E20190919_R0003_v2\"\n",
    "codebook_file = r\"D:\\MERFISH\\MERlin_Parameters\\codebooks\\codebook_alex_130gene.csv\"\n",
    "#codebook_file = r\"D:\\MERFISH\\MERlin_Parameters\\codebooks\\codebook_heart_tissue.csv\"\n",
    "expanded_codebook_file = r\"D:\\MERFISH\\MERlin_Parameters\\codebooks\\codebook_alex_130gene_expanded.csv\"\n",
    "#expanded_codebook_file = r\"D:\\MERFISH\\MERlin_Parameters\\codebooks\\codebook_heart_tissue_expanded.csv\"\n",
    "rnaseq_reference = r'D:\\MERFISH\\Random_Data\\U2OS_abundances_qz.rpkm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting decoded barcodes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea52acc6824b49a59a9cc51bd2650815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a26157fae164>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mraw_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalysis_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"Decode\\barcodes\\barcode_data_*.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbarcodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mraw_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbarcodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, mode, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m                     )\n\u001b[0;32m    406\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcandidate_only_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v_pathname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_close\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauto_close\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;31m# if there is an error, close the store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, key, where, start, stop, columns, iterator, chunksize, auto_close, **kwargs)\u001b[0m\n\u001b[0;32m    780\u001b[0m         )\n\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mselect_as_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self, coordinates)\u001b[0m\n\u001b[0;32m   1637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m         \u001b[1;31m# directly return the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1640\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(_start, _stop, _where)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[1;31m# function to call on iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_where\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_where\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[1;31m# create the iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, where, columns, **kwargs)\u001b[0m\n\u001b[0;32m   4476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4477\u001b[0m         \u001b[1;31m# apply the selection filters & axis orderings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4478\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4480\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mprocess_axes\u001b[1;34m(self, obj, columns)\u001b[0m\n\u001b[0;32m   3972\u001b[0m         \u001b[1;31m# reorder by any non_index_axes & limit to the select columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3973\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnon_index_axes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3974\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reindex_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3975\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3976\u001b[0m         \u001b[1;31m# apply the selection filters (but keep in the same order)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m_reindex_axis\u001b[1;34m(obj, axis, labels, other)\u001b[0m\n\u001b[0;32m   4645\u001b[0m         \u001b[0mslicer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4646\u001b[0m         \u001b[0mslicer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4647\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4648\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1416\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1419\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    820\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1837\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1133\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m-> 1135\u001b[1;33m                 \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m             )\n\u001b[0;32m   1137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   4575\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4576\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4577\u001b[1;33m                 \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4578\u001b[0m             )\n\u001b[0;32m   4579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m             new_blocks = [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1355\u001b[0m                             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m                             \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m                             \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m                         )\n\u001b[0;32m   1359\u001b[0m                     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m         new_values = algos.take_nd(\n\u001b[1;32m-> 1314\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m         )\n\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Counting decoded barcodes\")\n",
    "barcode_files = glob.glob(os.path.join(analysis_folder, r\"Decode\\barcodes\\barcode_data_*.h5\"))\n",
    "fovs = len(barcode_files)\n",
    "raw_count = 0\n",
    "for file in tqdm(glob.glob(os.path.join(analysis_folder, r\"Decode\\barcodes\\barcode_data_*.h5\"))):\n",
    "    barcodes = pd.read_hdf(file)\n",
    "    raw_count += len(barcodes)\n",
    "    \n",
    "print(\"Counting filtered barcodes\")\n",
    "filter_count = len(pd.read_csv(os.path.join(analysis_folder, r\"ExportBarcodes\\barcodes.csv\")))\n",
    "\n",
    "print(\"FOVS:\", fovs)\n",
    "print(raw_count, raw_count/fovs, filter_count, filter_count/fovs, filter_count/raw_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from scipy.linalg import norm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "def process_fov(filename, normcodes):\n",
    "    barcodes = pandas.read_hdf(filename)\n",
    "    fov = int(filename.split('_')[-1].split('.')[0])\n",
    "\n",
    "    #Subset for testing\n",
    "    #barcodes = barcodes.iloc[1000:1050]\n",
    "\n",
    "    #Get just the intensity columns for convenience\n",
    "    intensities = barcodes[[f'intensity_{i}' for i in range(16)]]\n",
    "    intensities = intensities.rename(columns=lambda x: 'intensity_' + str(int(x.split('_')[1])+1)) \n",
    "\n",
    "    #Find nearest\n",
    "    neighbors = NearestNeighbors(n_neighbors=1, algorithm='ball_tree')\n",
    "    neighbors.fit(normcodes)\n",
    "    distances, indexes = neighbors.kneighbors(intensities, return_distance=True)\n",
    "\n",
    "    rows = []\n",
    "    for i, index in enumerate(indexes):\n",
    "        barcode = codebook.iloc[index[0]]\n",
    "        ints = intensities.iloc[i]\n",
    "        test = pandas.concat([barcode, ints], axis=0)\n",
    "        rows.append(test)\n",
    "\n",
    "    df = pandas.DataFrame(rows)\n",
    "    df['fov'] = fov\n",
    "    \n",
    "    return df\n",
    "\n",
    "def error_stats(data):\n",
    "    c = Counter(data.filter(like='bit').sum(axis=1))\n",
    "    total = sum(c.values())\n",
    "    return pandas.Series([total, c[4] / total, c[5] / total, c[3] / total], index=[\"Barcodes\", \"Correct\", \"0->1 error\", \"1->0 error\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L2 normalize codebook\n",
    "import pandas\n",
    "\n",
    "codebook = pandas.read_csv(expanded_codebook_file)\n",
    "codes = codebook.filter(like='bit')\n",
    "normcodes = codes.apply(lambda row: row / norm(row), axis=1)\n",
    "\n",
    "files = glob.glob(os.path.join(analysis_folder, r\"AdaptiveFilterBarcodes\\barcodes\\barcode_data_*.h5\"))\n",
    "\n",
    "dfs = [process_fov(filename, normcodes) for filename in tqdm(files)]\n",
    "df = pandas.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Rate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will give the 0 -> 1 and 1 -> 0 error rates\n",
    "print(error_stats(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones2zeros = []\n",
    "zeros2ones = []\n",
    "for gene in df['name'].unique():\n",
    "    x = df[df['name'] == gene]\n",
    "    z = codebook[codebook['id'] == gene]\n",
    "    i = z.columns[(z == 1).iloc[0]]\n",
    "    o2z = pandas.DataFrame((len(x) - x[i].sum()) / len(x)).T\n",
    "    z2o = pandas.DataFrame(x[x.filter(like='bit').columns.difference(i)].sum() / len(x)).T\n",
    "    ones2zeros.append(o2z)\n",
    "    zeros2ones.append(z2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will export the bit errors to an excel sheet; change the name of the excel sheet if wanted in the ExcelWriter function. It will also give error visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def meltdata(df):\n",
    "    data = pandas.concat(df, axis=0)\n",
    "    data = data.rename(columns=lambda x: int(x.strip('bit')))\n",
    "    data = data.melt(value_vars=data.columns, var_name='Bit', value_name='Error rate')\n",
    "    return data\n",
    "\n",
    "d = meltdata(ones2zeros)\n",
    "d['Error type'] = '1 -> 0'\n",
    "d2 = meltdata(zeros2ones)\n",
    "d2['Error type'] = '0 -> 1'\n",
    "data = pandas.concat([d, d2])\n",
    "\n",
    "ax = sns.catplot(x=\"Bit\", y=\"Error rate\", row=\"Error type\", data=data, kind=\"bar\", height=2, aspect=3,\n",
    "    capsize=0.2, color='dodgerblue', order=sorted(data[\"Bit\"].unique()), sharey=False, sharex=False)\n",
    "ax.savefig(os.path.join(analysis_folder, \"biterror.png\"), dpi=300)\n",
    "average = {}\n",
    "average2 = {}\n",
    "for index, i in d.iterrows():\n",
    "    average[(i[\"Bit\"])] = []\n",
    "for index, i in d.iterrows():\n",
    "    average.get(i[\"Bit\"]).append(i[\"Error rate\"])\n",
    "for i in average:\n",
    "    thelist = average.get(i)\n",
    "    countj = 0\n",
    "    runningj = 0\n",
    "    for j in thelist:\n",
    "        if math.isnan(j) == False:\n",
    "            runningj += j\n",
    "            countj += 1\n",
    "    if countj > 0:\n",
    "        average2[i] = float(runningj/countj)\n",
    "average2 = pd.DataFrame(average2.items())\n",
    "average2.columns = [\"Bit\", \"Error\"]\n",
    "print(average2)\n",
    "\n",
    "average01 = {}\n",
    "for index, i in d2.iterrows():\n",
    "    average01[(i[\"Bit\"])] = []\n",
    "for index, i in d2.iterrows():\n",
    "    average01.get(i[\"Bit\"]).append(i[\"Error rate\"])\n",
    "for i in average01:\n",
    "    thelist = average01.get(i)\n",
    "    countj = 0\n",
    "    runningj = 0\n",
    "    for j in thelist:\n",
    "        if math.isnan(j) == False:\n",
    "            runningj += j\n",
    "            countj += 1\n",
    "    if countj > 0:\n",
    "        average01[i] = float(runningj/countj)\n",
    "average01 = pd.DataFrame(average01.items())\n",
    "average01.columns = [\"Bit\", \"Error\"]\n",
    "print(average01)\n",
    "\n",
    "with pd.ExcelWriter('3.xlsx') as writer:  \n",
    "    average2.to_excel(writer, sheet_name='Sheet_name_1')\n",
    "    average01.to_excel(writer, sheet_name='Sheet_name_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the error rate per FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fovs = df.groupby('fov').apply(error_stats)\n",
    "fovs['FOV'] = fovs.index\n",
    "fovs.columns = ['Count', 'Correct', '0 -> 1', '1 -> 0', 'FOV']\n",
    "fovs = fovs.melt(id_vars='FOV', value_vars=['0 -> 1', '1 -> 0'], var_name = 'Error type', value_name='Error rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fovplot(d, ax):\n",
    "    q1 = d['Error rate'].quantile(0.25)\n",
    "    q3 = d['Error rate'].quantile(0.75)\n",
    "    outlier = q3 + 1.5 * (q3 - q1)\n",
    "    outlier\n",
    "    ax.bar(d['FOV'], d['Error rate'], width=1)\n",
    "    ax.axhline(outlier, color='red', linestyle=':')\n",
    "    for i, row in d[d['Error rate'] >= outlier].iterrows():\n",
    "        ax.annotate(row['FOV'], (row['FOV'], row['Error rate']), ha='center', color='orangered', weight='heavy')\n",
    "    #ax.set_xlim(left=0, right=d['FOV'].max())\n",
    "    ax.set_xticks(list(range(0, d['FOV'].max(), 25)) + [d['FOV'].max()])\n",
    "    ax.set_xlabel(\"FOV\")\n",
    "    ax.set_ylabel(\"Error rate\")\n",
    "    ax.set_ylim(bottom=d['Error rate'].min()*0.75)\n",
    "        \n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(7,5))\n",
    "fovplot(fovs[fovs['Error type'] == '0 -> 1'], ax[0])\n",
    "fovplot(fovs[fovs['Error type'] == '1 -> 0'], ax[1])\n",
    "ax[0].set_title(\"Error type = 0 -> 1\")\n",
    "ax[1].set_title(\"Error type = 1 -> 0\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(analysis_folder, \"foverror.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene abundance Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can add gene names in using if you want to see their normalized counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation(xcounts, ycounts, xlabel, ylabel, outfile, omit=[]):\n",
    "    set1 = set(xcounts.keys())\n",
    "    set2 = set(ycounts.keys())\n",
    "    genes_to_consider = list(set1.intersection(set2))\n",
    "    x = [xcounts[gene] for gene in genes_to_consider if gene not in omit]\n",
    "    y = [ycounts[gene] for gene in genes_to_consider if gene not in omit]\n",
    "    using = []\n",
    "    #using.append(\"PRPF8\")\n",
    "\n",
    "    for gene in genes_to_consider: \n",
    "        if gene not in omit and gene in using:\n",
    "            print(gene, (10**ycounts[gene]))\n",
    "    num = []\n",
    "    count = 0\n",
    "    for gene in genes_to_consider:\n",
    "    #    if gene not in omit:\n",
    "    #        count += 1\n",
    "            #print(gene)\n",
    "    #        if gene == \"EGFR\":\n",
    "    #            print(10**y[count])\n",
    "            if gene not in omit:\n",
    "                num.append(gene) \n",
    "    \n",
    "    corr, pval = pearsonr(x,y)\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(x,p(x),\"r--\")\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(\"Pearson = %.3f\" %corr)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    for i, txt in enumerate(num):\n",
    "        plt.annotate(txt, (x[i], y[i]), size=8, textcoords=\"offset points\")\n",
    "    #plt.savefig(os.path.join(analysis_folder, outfile), dpi=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the merfish counts from our experiments, whichever barcode_counts.npy file that is desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_merfish_counts(filename, codebook):\n",
    "    gene_counts = np.load(filename)\n",
    "    ordered_genes = list(codebook['name'])\n",
    "    abundances = {}\n",
    "    for i, gene in enumerate(ordered_genes):\n",
    "        abundances[gene] = np.log10(gene_counts[i]+1)\n",
    "    return abundances\n",
    "\n",
    "#Load MERFISH counts\n",
    "codebook = pd.read_csv(codebook_file)\n",
    "#merfish_counts = load_merfish_counts(os.path.join(analysis_folder, r\"PlotPerformance\\filterplots\\FilteredBarcodesMetadata\\barcode_counts.npy\"), codebook)\n",
    "merfish_counts = load_merfish_counts(r\"D:\\MERFISH\\E20190920_R0004\\MERlin_Analysis\\E20190920_R0004_v4\\PlotPerformance\\filterplots\\FilteredBarcodesMetadata\\barcode_counts.npy\",codebook)\n",
    "#merfish_counts = load_merfish_counts(r\"D:\\MERFISH\\MERlin_Analysis\\E20201123_R0040\\PlotPerformance\\filterplots\\FilteredBarcodesMetadata\\barcode_counts.npy\",codebook)\n",
    "merfish_counts = load_merfish_counts(r\"D:\\MERFISH\\MERlin_Analysis\\E20201223_R0049_S2\\PlotPerformance\\filterplots\\FilteredBarcodesMetadata\\barcode_counts.npy\",codebook)\n",
    "#merfish_counts = load_merfish_counts(r\"C:\\Users\\amonell\\Documents\\barcode_counts.npy\",codebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the Moffitt PNAS rna-seq counts (old version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnas_rna = pd.read_csv(r'D:\\MERFISH\\Random_Data\\SRR987281.fpkm', sep=',')\n",
    "pnas_rna2 = pd.read_csv(r'D:\\MERFISH\\Random_Data\\SRR987282.fpkm', sep=',')\n",
    "pnas_rna3 = pd.read_csv(r'D:\\MERFISH\\Random_Data\\SRR987283.fpkm', sep=',')\n",
    "pnas1 = dict(zip(pnas_rna['gene_id'], pnas_rna['FPKM']))\n",
    "pnas2 = dict(zip(pnas_rna2['gene_id'], pnas_rna2['FPKM']))\n",
    "pnas3 = dict(zip(pnas_rna3['gene_id'], pnas_rna3['FPKM']))\n",
    "setpnas1 = set(pnas1.keys())\n",
    "setpnas2 = set(pnas2.keys())\n",
    "setpnas3 = set(pnas3.keys())\n",
    "genes_to_consider2 = setpnas1.intersection(setpnas2)\n",
    "genes_to_consider3 = list(genes_to_consider2.intersection(setpnas3))\n",
    "fin_dict = {}\n",
    "for gene in genes_to_consider3:\n",
    "    avg = (pnas1[gene] + pnas2[gene] + pnas3[gene])/3.0\n",
    "    fin_dict[gene] = np.log10(avg+1)\n",
    "    #fin_dict[gene] = avg + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the Moffitt PNAS rna-seq counts (new version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnas_rnaseq = pd.read_csv(r'D:\\PNAS2016Data\\data_for_release\\file_io\\PNAS2016_RNAseq_FPKM.csv', sep = ',')\n",
    "pnas_rnaseq_fin = dict(zip(pnas_rnaseq['geneName'], pnas_rnaseq['FPKM']))\n",
    "setprna = set(pnas_rnaseq_fin.keys())\n",
    "genes_to_prna = list(setprna)\n",
    "pnas_dict_rna = {}\n",
    "for gene in genes_to_prna:\n",
    "    pnas_dict_rna[gene] = np.log10(pnas_rnaseq_fin[gene]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold of 0 gives all genes, higher threshold closer to the total number of genes gives the lower count genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlowcounts(xcounts, ycounts):\n",
    "    omit = []\n",
    "    set1 = set(xcounts.keys())\n",
    "    set2 = set(ycounts.keys())\n",
    "    genes_to_consider = list(set1.intersection(set2))\n",
    "    #print(genes_to_consider)\n",
    "    #genes_to_consider = zcounts\n",
    "    x = [xcounts[gene] for gene in genes_to_consider if gene not in omit]\n",
    "    y = [ycounts[gene] for gene in genes_to_consider if gene not in omit]\n",
    "    z = [math.sqrt(y[z]**2 + x[z]**2) for z in range(len(x))]\n",
    "    threshold = 0\n",
    "    temp = []\n",
    "    while len(temp) < threshold:\n",
    "        minval = min(z)\n",
    "        minindex = z.index(minval)\n",
    "        temp.append(genes_to_consider[minindex])\n",
    "        del z[minindex]\n",
    "        del genes_to_consider[minindex]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold of total gene number gives all genes, lower threshold closer to 0 gives higher count genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gethighcounts(xcounts, ycounts):\n",
    "    omit = []\n",
    "    set1 = set(xcounts.keys())\n",
    "    set2 = set(ycounts.keys())\n",
    "    genes_to_consider = list(set1.intersection(set2))\n",
    "    #genes_to_consider = zcounts\n",
    "    x = [xcounts[gene] for gene in genes_to_consider if gene not in omit]\n",
    "    y = [ycounts[gene] for gene in genes_to_consider if gene not in omit]\n",
    "    z = [math.sqrt(y[z]**2 + x[z]**2) for z in range(len(x))]\n",
    "    threshold = 130\n",
    "    temp = []\n",
    "    while len(temp) < threshold:\n",
    "        minval = min(z)\n",
    "        minindex = z.index(minval)\n",
    "        temp.append(genes_to_consider[minindex])\n",
    "        del z[minindex]\n",
    "        del genes_to_consider[minindex]\n",
    "    t = [gene for gene in genes_to_consider if gene not in temp]\n",
    "    #t.append('MALAT1')\n",
    "    return t\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in our rna-seq values, PNAS MERFISH Counts, and correlating.  Can omit high count or low count genes if wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load RNA-seq rpkm values\n",
    "col = pd.read_csv(r'D:\\MERFISH\\Random_Data\\U2OS_abundances_qz.rpkm', sep='\\t')\n",
    "#Take the average rpkm of both replicates\n",
    "col['mean'] = col[['bam.RQZ90.nodup.bam','bam.RQZ91.nodup.bam']].mean(axis=1)\n",
    "#Log transform the data and turn it into a dictionary\n",
    "rnaseq_counts = dict(zip(col['Geneid'], np.log10(col['mean']+1)))\n",
    "\n",
    "new_pnas = pd.read_csv(r'D:\\MERFISH\\Random_Data\\PNAS2016_MERFISH_counts_new.csv', sep=',', header = None)\n",
    "new_pnas.columns = ['name', 'counts'] \n",
    "\n",
    "for i in range(len(pnas['name'])):\n",
    "    pnas['name'][i] = pnas['name'][i][:-1]\n",
    "\n",
    "new_pnas_counts = dict(zip(new_pnas['name'], np.log10(new_pnas['counts']+1)))\n",
    "\n",
    "plot_correlation(xcounts=new_pnas_counts, \n",
    "                   ycounts=merfish_counts, \n",
    "                   xlabel='Log PNAS MERFISH counts', \n",
    "                   ylabel='Log Experiment 4-3D MERFISH Counts', \n",
    "                   outfile='RNASeq_corr.png',\n",
    "                   omit=[])#gethighcounts(xer, yer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How a gene behaves in an individual experiment after cellpose and edge cell removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start here\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20190919_R0003\\cy3_320diameter_slice30'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20190920_R0004\\cyto_fullsize_320diameter'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20190930_R0006\\cy3_320diameter_slice30'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20201106_R0034\\cyto_fullsize_320diameter'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20201222_R0049_S1\\cyto_fullsize_320diameter'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20201123_R0040\\cyto_fullsize'\n",
    "mask_folder = r'D:\\MERFISH\\Segmentation\\E20200310_R0022\\cy3_320diameter_slice30'\n",
    "\n",
    "#read in segmentation mask\n",
    "edgecells = set()\n",
    "for fov, filename in enumerate(sorted(glob.glob(os.path.join(mask_folder, '*_cp_masks.png')))):\n",
    "    mask = np.asarray(PIL.Image.open(filename))\n",
    "    edgecells.update(10000*fov + np.unique(np.concatenate([mask[:,0], mask[:,-1], mask[0,:], mask[-1,:]])))\n",
    "    \n",
    "    \n",
    "#table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201106_R0034\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\Archived_Experiments\\E20190919_R0003\\MERlin_Analysis\\E20190919_R0003_v2\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\E20190920_R0004\\MERlin_Analysis\\E20190920_R0004_v4\\single_cell_analysis_cyto_fullsize_320diameter\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\Archived_Experiments\\E20190930_R0006\\MERlin_Analysis\\E20190930_R0006\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201106_R0035\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201223_R0049_S2\\single_cell_analysis_cyto_fullsize_320diameter\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201222_R0049_S1\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201123_R0040\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\E20200310_R0022\\MERlin_Analysis\\E20200310_R0022\\single_cell_analysis_cy3_320diameter_slice30\\single_cell_raw_counts.csv\")\n",
    "\n",
    "\n",
    "table = pd.read_csv(\"D:\\MERFISH\\E20200310_R0022\\MERlin_Analysis\\E20200310_R0022\\single_cell_analysis_cy3_320diameter_slice30\\single_cell_raw_counts.csv\")\n",
    "#filter out the cells on the edges\n",
    "table = table[~table['cell_id'].isin(edgecells)] \n",
    "for index, row in table.iterrows():\n",
    "    total = sum(row[1:])\n",
    "    for i in range(len(row)):\n",
    "        if i != 0:\n",
    "            row[i] = float(row[i]/total)*1000000\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "#Get the specific gene from the table and perform calculations\n",
    "prp_vals = table[\"NOTCH2\"].to_list()\n",
    "average_per_cell = sum(prp_vals)/len(prp_vals)\n",
    "num_cells = len(prp_vals)\n",
    "std_dev_cell = statistics.stdev(prp_vals)\n",
    "\n",
    "#The total number of gene counts across all cells\n",
    "print(sum(prp_vals))\n",
    "#The total number of cells after filtering in the experiment\n",
    "print(num_cells)\n",
    "#The average number of gene counts per cell\n",
    "print(average_per_cell)\n",
    "#The standard deviation of the number of gene counts per cell\n",
    "print(std_dev_cell)\n",
    "#The standard deviation of the number of gene counts per cell divided by the average number of gene counts per cell\n",
    "print(std_dev_cell/average_per_cell)\n",
    "\n",
    "histo = pd.DataFrame({'Experiment 22 NOTCH2 Counts Per Cell': table[\"NOTCH2\"].to_list()})\n",
    "plot = histo.plot.hist(bins = 100)\n",
    "fig = plot.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assorted gene metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetypes = table.columns[1:]\n",
    "prpvals_list = []\n",
    "average_per_cell_list = []\n",
    "num_cells_list = []\n",
    "std_list = []\n",
    "for i in genetypes:\n",
    "    prp_vals = table[i].to_list()\n",
    "    average_per_cell = sum(prp_vals)/len(prp_vals)\n",
    "    num_cells = len(prp_vals)\n",
    "    std_dev_cell = statistics.stdev(prp_vals)\n",
    "    prpvals_list.append(sum(prp_vals))\n",
    "    average_per_cell_list.append(average_per_cell)\n",
    "    num_cells_list.append(num_cells)\n",
    "    std_list.append(std_dev_cell)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = pd.DataFrame({'Experiment 22 All genes total number of gene counts': prpvals_list}).plot.hist(bins = 100)\n",
    "fig = plot.get_figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = pd.DataFrame({'Experiment 22 average number of gene counts per cell after filtering': average_per_cell_list}).plot.hist(bins = 100)\n",
    "fig = plot.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = pd.DataFrame({'Experiment 22 standard deviation of gene counts per cell after filtering': std_list}).plot.hist(bins = 100)\n",
    "fig = plot.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = pd.DataFrame({'Experiment 22 standard deviation of gene counts per cell after filtering': std_list}).plot.hist(bins = 100)\n",
    "fig = plot.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing all experiments at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_folders = ['D:\\MERFISH\\Segmentation\\E20190919_R0003\\cy3_320diameter_slice30','D:\\MERFISH\\Segmentation\\E20190920_R0004\\cyto_fullsize_320diameter', 'D:\\MERFISH\\Segmentation\\E20190930_R0006\\cy3_320diameter_slice30', 'D:\\MERFISH\\Segmentation\\E20201106_R0034\\cyto_fullsize_320diameter', 'D:\\MERFISH\\Segmentation\\E20201222_R0049_S1\\cyto_fullsize_320diameter', 'D:\\MERFISH\\Segmentation\\E20201123_R0040\\cyto_fullsize', 'D:\\MERFISH\\Segmentation\\E20200310_R0022\\cy3_320diameter_slice30', 'D:\\MERFISH\\Segmentation\\E20201223_R0049_S2\\cyto_fullsize_320diameter']\n",
    "raw_counts_folders = [\"D:\\MERFISH\\Archived_Experiments\\E20190919_R0003\\MERlin_Analysis\\E20190919_R0003_v2\\single_cell_raw_counts.csv\", \"D:\\MERFISH\\E20190920_R0004\\MERlin_Analysis\\E20190920_R0004_v4\\single_cell_analysis_cyto_fullsize_320diameter\\single_cell_raw_counts.csv\", \"D:\\MERFISH\\Archived_Experiments\\E20190930_R0006\\MERlin_Analysis\\E20190930_R0006\\single_cell_raw_counts.csv\", \"D:\\MERFISH\\MERlin_Analysis\\E20201106_R0034\\single_cell_raw_counts.csv\", \"D:\\MERFISH\\MERlin_Analysis\\E20201222_R0049_S1\\single_cell_raw_counts.csv\", \"D:\\MERFISH\\MERlin_Analysis\\E20201123_R0040\\single_cell_raw_counts.csv\", \"D:\\MERFISH\\E20200310_R0022\\MERlin_Analysis\\E20200310_R0022\\single_cell_analysis_cy3_320diameter_slice30\\single_cell_raw_counts.csv\", \"D:\\MERFISH\\MERlin_Analysis\\E20201223_R0049_S2\\single_cell_analysis_cyto_fullsize_320diameter\\single_cell_raw_counts.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlyexpressed = ['SPTBN1', 'COL5A1', 'HERC2', 'FASN', 'ANKRD52', 'MALAT1', 'PRKDC', 'FAM208B', 'USP9X', 'UBR5', 'TPR', 'LRP1', 'PLXNA1', 'CHST3', 'FAF2', 'PRPF8', 'CENPF', 'TLN1', 'AFF4', 'THBS1', 'DYNC1H1', 'ZNF592', 'CREBBP', 'PRRC2B', 'USP34', 'CKAP5', 'SRRM2', 'CBX5', 'FBN2', 'NOTCH2']\n",
    "lowlyexpressed = ['TMOD2', 'USP8', 'SMIM5', 'FAM184B', 'RBM20', 'CEMIP', 'BSN', 'MCF2L', 'SLC9A2', 'XKR5', 'SAMD12', 'SULT1C2', 'TSPAN3', 'NHSL2', 'THSD4', 'RP4-671O14.6', 'SCUBE3', 'PAPPA', 'C14orf132', 'AGO3', 'SOD2', 'SKP1', 'RNF152', 'KIAA1462', 'XDH', 'SLC35B4', 'DOPEY1', 'DSEL', 'CNR2', 'RAD51D']\n",
    "counts_sum_per_gene_all_cells = []\n",
    "gene_average_counts_per_cell = []\n",
    "std_deviation_per_gene = []\n",
    "divided_per_gene = []\n",
    "num_cells_exp = []\n",
    "order = ['Exp 3', 'Exp 4', 'Exp 6', 'Exp 34', 'Exp 49_S1', 'Exp 40', 'Exp 22', 'Exp 49_S2']\n",
    "for i in range(len(mask_folders)):\n",
    "    mask_folder = mask_folders[i]\n",
    "    table = pd.read_csv(raw_counts_folders[i])\n",
    "    \n",
    "    edgecells = set()\n",
    "    for fov, filename in enumerate(sorted(glob.glob(os.path.join(mask_folder, '*_cp_masks.png')))):\n",
    "        mask = np.asarray(PIL.Image.open(filename))\n",
    "        edgecells.update(10000*fov + np.unique(np.concatenate([mask[:,0], mask[:,-1], mask[0,:], mask[-1,:]])))\n",
    "    \n",
    "    table.head()\n",
    "    table = table[~table['cell_id'].isin(edgecells)] \n",
    "    for index, row in table.iterrows():\n",
    "        total = sum(row[1:])\n",
    "        for i in range(len(row)):\n",
    "            if i != 0:\n",
    "                row[i] = float(row[i]/total)*1000000\n",
    "        \n",
    "    prpvals_list = []\n",
    "    average_per_cell_list = []\n",
    "    num_cells_list = []\n",
    "    std_list = []\n",
    "    divided_list = []\n",
    "    for i in highlyexpressed:\n",
    "    #for i in genetypes:\n",
    "        prp_vals = table[i].to_list()\n",
    "        average_per_cell = sum(prp_vals)/len(prp_vals)\n",
    "        num_cells = len(prp_vals)\n",
    "        std_dev_cell = statistics.stdev(prp_vals)\n",
    "        prpvals_list.append(sum(prp_vals))\n",
    "        average_per_cell_list.append(average_per_cell)\n",
    "        num_cells_list.append(num_cells)\n",
    "        std_list.append(std_dev_cell)\n",
    "        divided_list.append(std_dev_cell/average_per_cell)\n",
    "    counts_sum_per_gene_all_cells.append(np.mean(prpvals_list))\n",
    "    gene_average_counts_per_cell.append(np.mean(average_per_cell_list))\n",
    "    std_deviation_per_gene.append(np.mean(std_list))\n",
    "    divided_per_gene.append(np.mean(divided_list))\n",
    "    num_cells_exp.append(np.mean(num_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(order,counts_sum_per_gene_all_cells)\n",
    "plt.title('Average sum of counts per gene across all cells')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(order,gene_average_counts_per_cell)\n",
    "plt.title('Average counts per gene per cell')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(order,std_deviation_per_gene)\n",
    "plt.title('Average standard deviation of gene counts across cells per experiment')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(order,divided_per_gene)\n",
    "plt.title('Average (standard deviation/average gene counts) across cells per experiment')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(order,num_cells_exp)\n",
    "plt.title('Average number of cells per experiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Cellpose Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlyexpressed = ['SPTBN1', 'COL5A1', 'HERC2', 'FASN', 'ANKRD52', 'MALAT1', 'PRKDC', 'FAM208B', 'USP9X', 'UBR5', 'TPR', 'LRP1', 'PLXNA1', 'CHST3', 'FAF2', 'PRPF8', 'CENPF', 'TLN1', 'AFF4', 'THBS1', 'DYNC1H1', 'ZNF592', 'CREBBP', 'PRRC2B', 'USP34', 'CKAP5', 'SRRM2', 'CBX5', 'FBN2', 'NOTCH2']\n",
    "lowlyexpressed = ['TMOD2', 'USP8', 'SMIM5', 'FAM184B', 'RBM20', 'CEMIP', 'BSN', 'MCF2L', 'SLC9A2', 'XKR5', 'SAMD12', 'SULT1C2', 'TSPAN3', 'NHSL2', 'THSD4', 'RP4-671O14.6', 'SCUBE3', 'PAPPA', 'C14orf132', 'AGO3', 'SOD2', 'SKP1', 'RNF152', 'KIAA1462', 'XDH', 'SLC35B4', 'DOPEY1', 'DSEL', 'CNR2', 'RAD51D']\n",
    "counts_sum_per_gene_all_cells = []\n",
    "gene_average_counts_per_cell = []\n",
    "std_deviation_per_gene = []\n",
    "divided_per_gene = []\n",
    "num_cells_exp = []\n",
    "order = ['Exp 3', 'Exp 4', 'Exp 6', 'Exp 34', 'Exp 49_S1', 'Exp 40', 'Exp 22', 'Exp 49_S2']\n",
    "for i in range(len(mask_folders)):\n",
    "    mask_folder = mask_folders[i]\n",
    "    table = pd.read_csv(raw_counts_folders[i])\n",
    "    \n",
    "    edgecells = set()\n",
    "    for fov, filename in enumerate(sorted(glob.glob(os.path.join(mask_folder, '*_cp_masks.png')))):\n",
    "        mask = np.asarray(PIL.Image.open(filename))\n",
    "        edgecells.update(10000*fov + np.unique(np.concatenate([mask[:,0], mask[:,-1], mask[0,:], mask[-1,:]])))\n",
    "    \n",
    "    table.head()\n",
    "    table = table[~table['cell_id'].isin(edgecells)] \n",
    "    for index, row in table.iterrows():\n",
    "        total = sum(row[1:])\n",
    "        for i in range(len(row)):\n",
    "            if i != 0:\n",
    "                row[i] = float(row[i]/total)*1000000\n",
    "        \n",
    "    prpvals_list = []\n",
    "    average_per_cell_list = []\n",
    "    num_cells_list = []\n",
    "    std_list = []\n",
    "    divided_list = []\n",
    "    for i in genetypes:\n",
    "    #for i in genetypes:\n",
    "        prp_vals = table[i].to_list()\n",
    "        average_per_cell = sum(prp_vals)/len(prp_vals)\n",
    "        num_cells = len(prp_vals)\n",
    "        std_dev_cell = statistics.stdev(prp_vals)\n",
    "        prpvals_list.append(sum(prp_vals))\n",
    "        average_per_cell_list.append(average_per_cell)\n",
    "        num_cells_list.append(num_cells)\n",
    "        std_list.append(std_dev_cell)\n",
    "        divided_list.append(std_dev_cell/average_per_cell)\n",
    "    counts_sum_per_gene_all_cells.append(prpvals_list)\n",
    "    gene_average_counts_per_cell.append(average_per_cell_list)\n",
    "    std_deviation_per_gene.append(std_list)\n",
    "    divided_per_gene.append(divided_list)\n",
    "    num_cells_exp.append(num_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyz = ['Blank-1','Blank-10','Blank-2','Blank-3','Blank-4','Blank-5','Blank-6','Blank-7','Blank-8','Blank-9']\n",
    "for i in keyz:\n",
    "    del new_pnas_counts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercounts = {}\n",
    "for v in range(len(counts_sum_per_gene_all_cells)):\n",
    "    cts = np.log10(counts_sum_per_gene_all_cells[v])\n",
    "    for i in range(len(cts)):\n",
    "        mercounts[genetypes[i]] = float(cts[i])\n",
    "\n",
    "    plot_correlation(xcounts=new_pnas_counts,#pnas_dict_rna,#new_pnas_counts, \n",
    "                       ycounts=mercounts, #zcounts=genes_to_consider7,\n",
    "                       xlabel='Log PNAS MERFISH counts', \n",
    "                       ylabel='Log Experiment ' + order[v] + ' MERFISH Counts', \n",
    "                       outfile='RNASeq_corr.png',\n",
    "                       omit=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Expression Rank Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvals = {}\n",
    "for i in range(len(mask_folders)):\n",
    "    mask_folder = mask_folders[i]\n",
    "    table = pd.read_csv(raw_counts_folders[i])\n",
    "    \n",
    "    edgecells = set()\n",
    "    for fov, filename in enumerate(sorted(glob.glob(os.path.join(mask_folder, '*_cp_masks.png')))):\n",
    "        mask = np.asarray(PIL.Image.open(filename))\n",
    "        edgecells.update(10000*fov + np.unique(np.concatenate([mask[:,0], mask[:,-1], mask[0,:], mask[-1,:]])))\n",
    "    \n",
    "    table.head()\n",
    "    table = table[~table['cell_id'].isin(edgecells)] \n",
    "    for index, row in table.iterrows():\n",
    "        total = sum(row[1:])\n",
    "        for i in range(len(row)):\n",
    "            if i != 0:\n",
    "                row[i] = float(row[i]/total)*1000000\n",
    "    \n",
    "    ziplist_gene = []\n",
    "    for k in genetypes:\n",
    "        pp = table[k].tolist()\n",
    "        pp = sum(pp)/len(pp)\n",
    "        ziplist_gene.append(pp)\n",
    "        \n",
    "    ziplist_percent = []\n",
    "\n",
    "    for z in ziplist_gene:\n",
    "        countt = 0\n",
    "        for b in ziplist_gene:\n",
    "            if b > z:\n",
    "                countt += 1\n",
    "        ziplist_percent.append(countt/len(ziplist_gene))       \n",
    "    \n",
    "    for k in range(len(genetypes)):  \n",
    "        if genetypes[k] in topvals:   \n",
    "            topvals[genetypes[k]].append(ziplist_percent[k])\n",
    "        else:\n",
    "            topvals[genetypes[k]] = [ziplist_percent[k]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene in topvals:    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(order,topvals.get(gene))\n",
    "    plt.title('Percent counts higher than ' + gene)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(order,topvals.get('SOD2'))\n",
    "plt.title('Percent counts higher than SOD2')# + gene)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-test gel-embedded non-embedded expression rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sst\n",
    "\n",
    "df = pd.DataFrame([statistics.stdev(topvals.get(n)) for n in topvals])\n",
    "df.columns = ['Std Dev']\n",
    "df.index = [n for n in topvals]\n",
    "df.sort_values(by = ['Std Dev'], axis = 0)\n",
    "\n",
    "df13 = pd.DataFrame([statistics.stdev(topvals.get(n)[:3]) for n in topvals])\n",
    "df13.columns = ['Std Dev']\n",
    "df13.index = [n for n in topvals]\n",
    "df13=np.sort(df13['Std Dev'])\n",
    "\n",
    "\n",
    "ttest = sst.ttest_ind(df, df13)\n",
    "print(ttest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNAseq Relative Expression Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pnas_dict_rna_names = [i for i in pnas_dict_rna]\n",
    "pnas_dict_rna_values = [pnas_dict_rna.get(i) for i in pnas_dict_rna]\n",
    "df_rna = pd.DataFrame(zip(pnas_dict_rna_names, pnas_dict_rna_values))\n",
    "df_rna.columns = ['gene', 'ct']\n",
    "df_rna = df_rna.sort_values(by=['ct'])\n",
    "df_rna['higher_than'] = [i for i in range(len(df_rna['gene']))]\n",
    "\n",
    "df_rna_dict = {}\n",
    "for i in range(len(df_rna['gene'])):\n",
    "    df_rna_dict[df_rna['gene'][i]] = df_rna['higher_than'][i]\n",
    "    \n",
    "vals = [topvals.get(n)[0] for n in topvals]\n",
    "genes = [n for n in topvals]\n",
    "df_rna2 = pd.DataFrame(zip(genes, vals))\n",
    "df_rna2.columns = ['gene', 'ct']\n",
    "df_rna2 = df_rna2.sort_values(by=['ct'])\n",
    "df_rna2['higher_than'] = [(i-129)*-1 for i in range(len(df_rna2['gene']))]\n",
    "\n",
    "df_mer_dict = {}\n",
    "for i in range(len(df_rna2['gene'])):\n",
    "    df_mer_dict[df_rna2['gene'][i]] = df_rna2['higher_than'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation2(xcounts, ycounts, xlabel, ylabel, outfile, omit=[]):\n",
    "    set1 = set(xcounts.keys())\n",
    "    set2 = set(ycounts.keys())\n",
    "    genes_to_consider = list(set1.intersection(set2))\n",
    "    #genes_to_consider = zcounts\n",
    "    x = [xcounts[gene] for gene in genes_to_consider if gene not in omit]\n",
    "    y = [ycounts[gene] for gene in genes_to_consider if gene not in omit]\n",
    "    using = []\n",
    "    #using.append(\"PRPF8\")\n",
    "    #using.append(\"BRCA2\")\n",
    "    #using.append(\"MALAT1\")\n",
    "    #using.append(\"EGFR\")\n",
    "    #using.append(\"CENPF\")\n",
    "    #using.append(\"MED14\")\n",
    "    #using.append(\"CBX5\")\n",
    "    #using.append(\"SMARCA5\")\n",
    "    #using.append(\"IGF2R\")\n",
    "    #using.append(\"FBN2\")\n",
    "    #using.append(\"THBS1\")\n",
    "    for gene in genes_to_consider: \n",
    "        if gene not in omit and gene in using:\n",
    "            print(gene, (10**ycounts[gene]))\n",
    "    num = []\n",
    "    count = 0\n",
    "    for gene in genes_to_consider:\n",
    "    #    if gene not in omit:\n",
    "    #        count += 1\n",
    "            #print(gene)\n",
    "    #        if gene == \"EGFR\":\n",
    "    #            print(10**y[count])\n",
    "            if gene not in omit:\n",
    "                num.append(gene) \n",
    "    \n",
    "    corr, pval = pearsonr(x,y)\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(x,p(x),\"r--\")\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(\"Pearson = %.3f\" %corr)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlim(-5, 135)\n",
    "    plt.ylim(-5, 135)\n",
    "    plt.xlabel(xlabel)\n",
    "    for i, txt in enumerate(num):\n",
    "        plt.annotate(txt, (x[i], y[i]), size=8)#, textcoords= \"figure fraction\")\n",
    "    #plt.savefig(os.path.join(analysis_folder, outfile), dpi=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation2(xcounts=df_rna_dict,#pnas_dict_rna,#new_pnas_counts, \n",
    "                    ycounts=df_mer_dict, #zcounts=genes_to_consider7,\n",
    "                    xlabel='PNAS RNA Rank', \n",
    "                    ylabel='MERFISH Counts Rank Exp 4', \n",
    "                    outfile='RNASeq_corr.png',\n",
    "                    omit=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find 2 bit similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter gene name below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene2bit = \"SOD2\"\n",
    "codebook = pandas.read_csv(codebook_file)\n",
    "codebook2 = codebook[~codebook['name'].str.contains(\"blank\")]\n",
    "codebook2 = codebook2[~codebook2['name'].str.contains(\"notarget\")]\n",
    "codebook_dict = {}\n",
    "for index, codebook2r in codebook2.iterrows():\n",
    "\n",
    "    addlist = [codebook2r.bit1, codebook2r.bit2, codebook2r.bit3, codebook2r.bit4, codebook2r.bit5, codebook2r.bit6, codebook2r.bit7, codebook2r.bit8, codebook2r.bit9, codebook2r.bit10, codebook2r.bit11, codebook2r.bit12, codebook2r.bit13, codebook2r.bit14, codebook2r.bit15, codebook2r.bit16]\n",
    "    codebook_dict[codebook2r.id] = addlist\n",
    "\n",
    "spots = [i+1 for i in range(len(codebook_dict.get(gene2bit))) if codebook_dict.get(gene2bit)[i] == 1]\n",
    "spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_id = codebook2['id'].tolist()\n",
    "genes_the_same = []\n",
    "bits_the_same = []\n",
    "for ij in code_id:\n",
    "    if ij == gene2bit:\n",
    "        continue\n",
    "    else:\n",
    "        spots_compare = [i for i in range(len(codebook_dict.get(ij))) if codebook_dict.get(ij)[i] == 1]\n",
    "        spots_compare = [k+1 for k in spots_compare if k+1 in spots]\n",
    "\n",
    "        if len(spots_compare) >= 2:\n",
    "            genes_the_same.append(ij)\n",
    "            bits_the_same.append([e for e in spots_compare])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(order,topvals.get(gene2bit))\n",
    "plt.title('Percent counts higher than ' + gene2bit)# + gene)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing specific similar bits as outputted 2 cells above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcount = 0\n",
    "#enter the gene bits you want to look at i.e [1, 7]\n",
    "bits_included = [16]\n",
    "for f in genes_the_same:\n",
    "    if len([i for i in bits_included if i in bits_the_same[bcount]]) == len(bits_included):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_axes([0,0,1,1])\n",
    "        ax.bar(order,topvals.get(f))\n",
    "        plt.title('Percent counts higher than ' + f + ', Bits: ' + str(bits_the_same[bcount]))# + gene)\n",
    "        plt.show()\n",
    "    bcount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find total experiment statistics by looking at the raw counts for all genes at once per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20190919_R0003\\cy3_320diameter_slice30'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20190920_R0004\\cyto_fullsize_320diameter'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20190930_R0006\\cy3_320diameter_slice30'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20201106_R0034\\cyto_fullsize_320diameter'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20201222_R0049_S1\\cyto_fullsize_320diameter'\n",
    "#mask_folder = r'D:\\MERFISH\\Segmentation\\E20201123_R0040\\cyto_fullsize'\n",
    "mask_folder = r'D:\\MERFISH\\Segmentation\\E20201106_R0035\\cyto_fullsize_320diameter'\n",
    "\n",
    "edgecells = set()\n",
    "for fov, filename in enumerate(sorted(glob.glob(os.path.join(mask_folder, '*_cp_masks.png')))):\n",
    "    mask = np.asarray(PIL.Image.open(filename))\n",
    "    edgecells.update(10000*fov + np.unique(np.concatenate([mask[:,0], mask[:,-1], mask[0,:], mask[-1,:]])))\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201106_R0034\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\Archived_Experiments\\E20190919_R0003\\MERlin_Analysis\\E20190919_R0003_v2\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\E20190920_R0004\\MERlin_Analysis\\E20190920_R0004_v4\\single_cell_analysis_cyto_fullsize_320diameter\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\Archived_Experiments\\E20190930_R0006\\MERlin_Analysis\\E20190930_R0006\\single_cell_raw_counts.csv\")\n",
    "table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201106_R0035\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201223_R0049_S2\\single_cell_analysis_cyto_fullsize_320diameter\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201222_R0049_S1\\single_cell_raw_counts.csv\")\n",
    "#table = pd.read_csv(\"D:\\MERFISH\\MERlin_Analysis\\E20201123_R0040\\single_cell_raw_counts.csv\")\n",
    "table = table[~table['cell_id'].isin(edgecells)] \n",
    "#for index, row in table.iterrows():\n",
    "#    total = sum(row[1:])\n",
    "#    for i in range(len(row)):\n",
    "#        if i != 0:\n",
    "#            row[i] = float(row[i]/total)*1000000\n",
    "import statistics \n",
    "\n",
    "table[\"TotalVals\"] = table[list(table.columns)].sum(axis=1)\n",
    "total_vals = table[\"TotalVals\"].to_list()\n",
    "average_per_cell = sum(total_vals)/len(total_vals)\n",
    "num_cells = len(total_vals)\n",
    "std_dev_cell = statistics.stdev(total_vals)\n",
    "\n",
    "print(sum(total_vals))\n",
    "#print(sum(prp_vals))\n",
    "print(num_cells)\n",
    "print(average_per_cell)\n",
    "print(std_dev_cell)\n",
    "print(std_dev_cell/average_per_cell)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "histo = pd.DataFrame({'Experiment 40 Counts Per Cell': total_vals})\n",
    "binwidth = max(total_vals)/40\n",
    "plot = histo.plot.hist( bins=np.arange(min(total_vals), max(total_vals) + binwidth, binwidth))\n",
    "fig = plot.get_figure()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
